{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "df = pd.read_csv('../data/train_data.csv')\n",
    "df.movie_title = df.movie_title.str[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Base code : https://github.com/mickeykedia/Matrix-Factorization-ALS/blob/master/ALS%20Python%20Implementation.py\n",
    "class AlternatingLeastSquares():\n",
    "    def __init__(self, R, k, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        # init latent features\n",
    "        self._users = np.random.normal(size=(self._num_users, self._k))\n",
    "        self._items = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        self._user_error = 0; self._item_error = 0; \n",
    "        for epoch in range(self._epochs):\n",
    "            for i, Ri in enumerate(self._R):\n",
    "                self._users[i] = self.user_latent(i, Ri)\n",
    "                self._user_error = self.cost()\n",
    "\n",
    "            for j, Rj in enumerate(self._R.T):\n",
    "                self._items[j] = self.item_latent(j, Rj)\n",
    "                self._item_error = self.cost()\n",
    "\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "\n",
    "            # print status\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "        xi, yi = self._R.nonzero()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - self.get_prediction(x, y), 2)\n",
    "        return np.sqrt(cost/len(xi))\n",
    "\n",
    "\n",
    "    def user_latent(self, i, Ri):\n",
    "        \"\"\"\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param Ri: Rating of user index i\n",
    "        :return: convergence value of user latent of i index\n",
    "        \"\"\"\n",
    "\n",
    "        du = np.linalg.solve(np.dot(self._items.T, np.dot(np.diag(Ri), self._items)) + self._reg_param * np.eye(self._k),\n",
    "                                   np.dot(self._items.T, np.dot(np.diag(Ri), self._R[i].T))).T\n",
    "        return du\n",
    "\n",
    "    def item_latent(self, j, Rj):\n",
    "        \"\"\"\n",
    "        :param error: rating - prediction error\n",
    "        :param j: item index\n",
    "        :param Rj: Rating of item index j\n",
    "        :return: convergence value of itemr latent of j index\n",
    "        \"\"\"\n",
    "\n",
    "        di = np.linalg.solve(np.dot(self._users.T, np.dot(np.diag(Rj), self._users)) + self._reg_param * np.eye(self._k),\n",
    "                                 np.dot(self._users.T, np.dot(np.diag(Rj), self._R[:, j])))\n",
    "        return di\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._users[i, :].dot(self._items[j, :].T)\n",
    "\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._users.dot(self._items.T)\n",
    "\n",
    "\n",
    "\n",
    "# run example\n",
    "if __name__ == \"__main__\":\n",
    "    # rating matrix - User X Item : (7 X 5)\n",
    "    R = np.array([\n",
    "        [1, 0, 0, 1, 3],\n",
    "        [2, 0, 3, 1, 1],\n",
    "        [1, 2, 0, 5, 0],\n",
    "        [1, 0, 0, 4, 4],\n",
    "        [2, 1, 5, 4, 0],\n",
    "        [5, 1, 5, 4, 0],\n",
    "        [0, 0, 0, 1, 0],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "tags_file ='/Users/paulthompson/Documents/MSAN_Files/Spr2_Distributed/HW1/movies/tags.txt'\n",
    "ratings_file = '/Users/paulthompson/Documents/MSAN_Files/Spr2_Distributed/HW1/movies/ratings.txt'\n",
    "movies_file = '/Users/paulthompson/Documents/MSAN_Files/Spr2_Distributed/HW1/movies/movies.txt'\n",
    "\n",
    "def getInitialMatrix():\n",
    "    '''\n",
    "    Gets data from files and creates user-item matrices\n",
    "    :return: A, R user-item matrices\n",
    "    '''\n",
    "    tags = pd.read_table(tags_file, sep=':', header=None, names=['user_id', 'movie_id', 'tag', 'timestamp'])\n",
    "    ratings = pd.read_table(ratings_file, sep=':', header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "    movies = pd.read_table(movies_file, sep=':', header=None, names=['movie_id', 'title', 'genres'])\n",
    "\n",
    "    print \"Join movies, ratings, and tags data frames together...\"\n",
    "    combined_df = ratings.join(movies, on=['movie_id'], rsuffix='_r').join(tags, on=['movie_id'], rsuffix='_t')\n",
    "    del combined_df['movie_id_r']; del combined_df['user_id_t']; del combined_df['movie_id_t']; del combined_df['timestamp_t']\n",
    "\n",
    "    combined_df = combined_df[0:5054]\n",
    "\n",
    "    print \"Getting 'A' matrix with rows: user and columns: movies...\"\n",
    "    A = combined_df.pivot_table(columns=['movie_id'], index=['user_id'], values='rating').fillna(0).values\n",
    "\n",
    "    print \" 'A' matrix shape is\", A.shape\n",
    "\n",
    "    print \"Getting 'R' Binary Matrix of rating or no rating...\"\n",
    "    R = A>0.5; R[R == True] = 1; R[R == False] = 0; R = R.astype(np.float64, copy=False)\n",
    "\n",
    "    return A, R\n",
    "\n",
    "def runALS(A, R, n_factors, n_iterations, lambda_):\n",
    "    '''\n",
    "    Runs Alternating Least Squares algorithm in order to calculate matrix.\n",
    "    :param A: User-Item Matrix with ratings\n",
    "    :param R: User-Item Matrix with 1 if there is a rating or 0 if not\n",
    "    :param n_factors: How many factors each of user and item matrix will consider\n",
    "    :param n_iterations: How many times to run algorithm\n",
    "    :param lambda_: Regularization parameter\n",
    "    :return:\n",
    "    '''\n",
    "    print \"Initiating \"\n",
    "    lambda_ = 0.1; n_factors = 3; n, m = A.shape; n_iterations = 20\n",
    "    Users = 5 * np.random.rand(n, n_factors)\n",
    "    Items = 5 * np.random.rand(n_factors, m)\n",
    "\n",
    "    def get_error(A, Users, Items, R):\n",
    "        # This calculates the MSE of nonzero elements\n",
    "        return np.sum((R * (A - np.dot(Users, Items))) ** 2) / np.sum(R)\n",
    "\n",
    "    MSE_List = []\n",
    "\n",
    "    print \"Starting Iterations\"\n",
    "    for iter in range(n_iterations):\n",
    "        for i, Ri in enumerate(R):\n",
    "            Users[i] = np.linalg.solve(np.dot(Items, np.dot(np.diag(Ri), Items.T)) + lambda_ * np.eye(n_factors),\n",
    "                                       np.dot(Items, np.dot(np.diag(Ri), A[i].T))).T\n",
    "        print \"Error after solving for User Matrix:\", get_error(A, Users, Items, R)\n",
    "\n",
    "        for j, Rj in enumerate(R.T):\n",
    "            Items[:,j] = np.linalg.solve(np.dot(Users.T, np.dot(np.diag(Rj), Users)) + lambda_ * np.eye(n_factors),\n",
    "                                     np.dot(Users.T, np.dot(np.diag(Rj), A[:, j])))\n",
    "        print \"Error after solving for Item Matrix:\", get_error(A, Users, Items, R)\n",
    "\n",
    "        MSE_List.append(get_error(A, Users, Items, R))\n",
    "        print '%sth iteration is complete...' % iter\n",
    "\n",
    "    print MSE_List\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(range(1, len(MSE_List) + 1), MSE_List); plt.ylabel('Error'); plt.xlabel('Iteration')\n",
    "    plt.title('Python Implementation MSE by Iteration \\n with %d users and %d movies' % A.shape);\n",
    "    plt.savefig('Python MSE Graph.pdf', format='pdf')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    A, R = getInitialMatrix()\n",
    "    runALS(A, R, n_factors = 3, n_iterations = 20, lambda_ = .1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2da6f8fc60d3bd5b90f8f5fcd48be407b787a8cf832d307f2e199849ddb8fb1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
